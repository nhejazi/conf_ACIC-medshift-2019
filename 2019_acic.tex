%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% baposter Landscape Poster
% LaTeX Template
% Version 1.0 (11/06/13)
%
% baposter Class Created by:
% Brian Amberg (baposter@brian-amberg.de)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
% PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[landscape,a0paper,fontscale=0.285]{baposter} % Adjust font scale/size

\usepackage{graphicx} % Required for including images
\graphicspath{{figs/}} % Directory in which figures are stored

\usepackage{amsmath} % For typesetting math
\usepackage{amssymb} % Adds new symbols to be used in math mode
\usepackage{mathtools}
\usepackage{bm}
\usepackage{url}
\usepackage[numbers]{natbib}
\usepackage{color,soul}
\usepackage{booktabs} % Top and bottom rules for tables
\usepackage{enumitem} % Used to reduce itemize/enumerate spacing
\usepackage{palatino} % Use the Palatino font
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures

\usepackage{multicol} % Required for multiple columns
\setlength{\columnsep}{1.5em} % Slightly increase the space between columns
\setlength{\columnseprule}{0mm} % No horizontal rule between columns

\newcommand{\compresslist}{ % Define a command to reduce spacing within itemize enumerate environments, this is used right after \begin{itemize} or \begin{enumerate}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}

\definecolor{lightblue}{rgb}{0.145,0.6666,1} % Defines color of content box headers

\begin{document}

\begin{poster} {
headerborder=closed, % Adds a border around the header of content boxes
colspacing=1em, % Column spacing
bgColorOne=white, % Background color for the gradient on the left side of the poster
bgColorTwo=white, % Background color for the gradient on the right side of the poster
borderColor=lightblue, % Border color
headerColorOne=black, % Background color for the header in the content boxes (left side)
headerColorTwo=lightblue, % Background color for the header in the content boxes (right side)
headerFontColor=white, % Text color for the header text in the content boxes
boxColorOne=white, % Background color of the content boxes
textborder=roundedleft, % Format of the border around content boxes, can be: none, bars, coils, triangles, rectangle, rounded, roundedsmall, roundedright or faded
eyecatcher=true, % Set to false for ignoring the left logo in the title and move the title left
headerheight=0.1\textheight, % Height of the header
headershape=roundedright, % Specify the rounded corner in the content box headers, can be: rectangle, small-rounded, roundedright, roundedleft or rounded
headerfont=\Large\bf\textsc, % Large, bold and sans serif font in the headers of content boxes
%textfont={\setlength{\parindent}{1.5em}}, % Uncomment for paragraph indentation
linewidth=2pt % Width of the border lines around content boxes
}
%----------------------------------------------------------------------------------------
% TITLE SECTION
%----------------------------------------------------------------------------------------
%
{\includegraphics[height=6.5em]{logo_berkeley.jpg}} % First university/lab logo on the left
{\bf\textit{\LARGE Nonparametric-efficient Causal Mediation Analysis for
    Stochastic Interventions}\vspace{0.01em}} % Poster title
{\textbf{Nima Hejazi, Mark van der Laan, and Iv{\'a}n D{\'\i}az} \\
  \textit{Graduate Group in Biostatistics \& Dept.~of Statistics, UC Berkeley}\\
  \textit{Division of Biostatistics, Dept.~of Healthcare Policy \& Research,
          Weill Cornell Medicine}}
    % Author names and institution
{\includegraphics[height=7.0em]{logo_weill.png}} % Second university/lab logo on the right

%-------------------------------------------------------------------------------
% OVERVIEW
%-------------------------------------------------------------------------------

\headerbox{Overview \& Motivations}{name=overview,column=0,row=0}{

\begin{itemize}\compresslist
  \setlength\itemsep{0.75em}
\item Using stochastic interventions, we present a decomposition of the
  \textit{population intervention effect} into \underline{direct} and
  \underline{indirect} effects.
  \begin{itemize}
    \item Define causal contrasts of effects of continuous and categorical
      exposures.
    \item Introduce a parameter necessary to construct direct and indirect
      effects.
  \end{itemize}
\item We propose estimators for constructing these direct and indirect effects:
  \begin{itemize}
    \item \textit{Classical}: G-computation and IPW based on parametric models.
    \item \textit{Efficient}: one-step and TML estimators leveraging machine
      learning.
  \end{itemize}
\item Our efficient estimators are asymptotically linear under
  $n^{1/4}$-consistency of nuisance functions (may use highly adaptive
  lasso).
\end{itemize}
\vspace{0.05cm} % When there are two boxes, some whitespace may need to be added
                % if the one on the right has more content
}

%-------------------------------------------------------------------------------
% INTRODUCTION
%-------------------------------------------------------------------------------

\headerbox{Software Implementation}
{name=introduction,column=1,row=0,bottomaligned=overview}{

\begin{itemize}\compresslist
  \setlength\itemsep{0.5em}
  \item The \underline{\texttt{medshift} \texttt{R} package}
    \cite{hejazi2019medshift} implements these estimators and leverages
    state-of-the-art machine learning in the procedure.
    \begin{itemize}
      \item Construction of all estimators via the eponymous \texttt{medshift()}
        function.
      \item Uses the \texttt{sl3} \texttt{R} package to incorporate machine
        learning facilities.
      \item Relies on the framework of the \texttt{tmle3} \texttt{R} package for
        TMLE implementation.
      \item Flexible cross-fitting implementation via the \texttt{origami}
        \texttt{R} package.
    \end{itemize}
  \item \texttt{sl3}, \texttt{tmle3}, and \texttt{origami} are core engines of
    the new \textbf{\texttt{tlverse}} software ecosystem.
    \begin{itemize}
      \item Check out \url{https://tlverse.org}
      \item Our handbook: \url{https://tlverse.org/tlverse-handbook}
    \end{itemize}
\end{itemize}
\vspace{0.05cm} % When there are two boxes, some whitespace may need to be added
                % if the one on the right has more content
}

%-------------------------------------------------------------------------------
% Methodology cont.
%-------------------------------------------------------------------------------

\headerbox{Construction of Nonparametric-Efficient Estimators}{name=results,
  column=2,span=2,row=0}{
\vspace{-0.35em}
\begin{itemize}
\itemsep0.1pt
\item To avoid entropy conditions on initial estimators, we rely on
  cross-validation \citep{zheng2011cross, chernozhukov2016double}, letting
  $\hat{\eta}_{j}$ be the estimator of $\eta = (g, e, m, \phi)$ and $j(i)$ the
  index of the validation set containing observation $i$.
\item A one-step estimator \citep{pfanzagl1982contributions} may be
  constructed by augmenting the substitution estimator with the auxiliary scores
  ($D^A$ and $D^Y$) in the efficient influence function (EIF), yielding
  \begin{equation*}
    \hat{\theta}_{\text{OS}}(\delta) = \frac{1}{n} \sum_{i = 1}^n
    D_{\hat{\eta}_{j(i)}, \delta}(O_i) =
      \frac{1}{n}\sum_{i = 1}^n \left\{D^Y_{\hat\eta_{j(i)}, \delta}(O_i) +
      D^A_{\hat\eta_{j(i)}, \delta}(O_i) + D^{Z,W}_{\hat\eta_{j(i)},
      \delta}(O_i) \right\}.
  \end{equation*}
\item A targeted minimum loss estimator (TMLE) may be constructed by using the
  efficient influence function to update components of the substitution
  estimator via a targeting procedure:
  \begin{equation*}
    \hat{\theta}_{\text{TMLE}}(\delta) = \int \frac{1}{n} \sum_{i=1}^n
    \hat{m}^{\star}_{j(i)}(Z, a, W)
    \hat{g}_{\delta, j(i)}^{\star}(a \mid W) d\kappa(a),
  \end{equation*}
  where
  $\hat{g}_{\delta}^{\star}(a \mid w)$ and $\hat{m}^{\star}(z,a,w)$ are
  generated via \textit{targeted} fluctuation regressions that tilt initial
  estimators towards solutions of the score equations $\sum_{i=1}^n D^A = 0$ and
  $\sum_{i=1}^n D^Y = 0$, respectively.
  %$\text{logit}(\hat{g}_{\delta,k\xi}) =
  %\text{logit}(\hat{g}_{\delta,(k-1)\xi}) + \xi_{\Delta g}^{\text{lfm}}
  %\mathbf{\textcolor{red}{H^A_{(k-1)\xi}}}$ and
  %$\text{logit}(\hat{m}_{k\xi}) = \text{logit}(\hat{m}_{(k-1)\xi}) +
  %\xi_{\Delta m}^{\text{lfm}}
  %\mathbf{\textcolor{blue}{H^Y_{(k-1)\xi}}}$.
  \begin{itemize}
    \item Unlike the one-step estimator, TMLE constructs a substitution
      estimator, respecting bounds.
    \item Targeting step uses the method of universal least favorable
      one-dimensional submodels \citep{vdl2016one}.
  \end{itemize}
\item Both are multiply robust, efficient, and allow construction of confidence
  intervals and hypothesis tests based on the EIF --- i.e.,
  $\mathbb{V}\hat{\theta}(\delta) \coloneqq \mathbb{V}D_{\hat{\eta},\delta}(O)$
  --- valid even when leveraging machine learning.
\end{itemize}
}

%-------------------------------------------------------------------------------
% REFERENCES
%-------------------------------------------------------------------------------

\headerbox{\small References}{name=references,column=2,above=bottom}{
\renewcommand{\section}[2]{\vskip 0.05em} % remove "References" section title
\tiny{ % Reduce the font size in this block
\setlength{\bibsep}{0.25pt}
\bibliographystyle{IEEEtranS}
%\nocite{*} % Insert publications even if they are not cited in the poster
\bibliography{2019_acic}
\compresslist
\vspace{-0.7em}
}
}

%-------------------------------------------------------------------------------
% CONTACT
%-------------------------------------------------------------------------------

\headerbox{\small But wait, there's more!}{name=ack,column=3,aligned=references,above=bottom}{
% This block is as tall as the references block
\begin{itemize}
\itemsep0pt
\item \textbf{N.~Hejazi}: \texttt{nhejazi@berkeley.edu};
      \textbf{M.~van der Laan}: \texttt{laan@berkeley.edu};
      \textbf{I.~D{\'\i}az}: \texttt{ild2005@med.cornell.edu}
\item \url{https://arxiv.org/abs/1901.02776}
\item Check out Iv{\'a}n's talk Friday morning!
\end{itemize}
\vspace{0.1cm}
}

%-------------------------------------------------------------------------------
% CONCLUSION
%-------------------------------------------------------------------------------

\headerbox{Results \& Discussion}
{name=conclusion,column=2,span=2,row=0,below=results,above=references}{

\vspace{0.25em}

\begin{multicols}{2}

%\begin{center}
%\vspace*{-0.5cm}
%\includegraphics[scale=0.37]{bias_composed_plot}
%%\captionof{figure}{This figure demonstrates...}
%\end{center}

%\begin{center}
%%\vspace*{-0.49cm}  % CHANGE THIS TO ALIGN IMAGES
%\includegraphics[scale=0.39]{rel_eff_composed_plot}
%%\captionof{figure}{This figure demonstrates...}
%\end{center}

%\vspace{-15pt}

\begin{itemize}
  \itemsep0pt
  \item All estimators approximately unbiased in large samples; TMLE outperforms
    one-step uniformly in smaller-sample settings.
  \item Inference is only valid for the one-step and TMLE when using machine
    learning (here, HAL) for estimating nuisance regressions.\\
\end{itemize}

\end{multicols}
}

%-------------------------------------------------------------------------------
% METHODS
%-------------------------------------------------------------------------------

\headerbox{Stochastic Population Intervention (In)Direct Effects}{name=method,
  column=0,span=2,below=overview, bottomaligned=references}{
% This block's bottom aligns with the bottom of the conclusion block

\begin{itemize}
\itemsep0.25pt
\item Consider $O = (W, A, Z, Y) \sim P_0 \in \mathcal{M}$, for $W$ a set of
  baseline covariates, $A$ an intervention, $Y$ the outcome, and $Z$ a mediator
  between $A$ and $Y$, with no assumptions on nonparametric model $\mathcal{M}$.
\item We decompose the total population intervention effect (PIE) in terms of a
  \textit{population intervention direct effect (PIDE)} and a \textit{population
  intervention indirect effect (PIIE)}:
  \begin{equation*}
    \psi(\delta) = \overbrace{\mathbb{E}\{Y(A_\delta, Z(A_\delta)) -
       Y(A_\delta, Z)\}}^{\text{PIIE}} + \overbrace{\mathbb{E}\{Y(A_\delta, Z)
       - Y(A, Z)\}}^{\text{PIDE}}.
  \end{equation*}
\item We show causal parameter $\mathbb{E}\{Y(A_\delta, Z)\}$ is identified by a
  functional of the distribution of $O$ \cite{diaz2019causal}:
  \begin{equation*}
    \theta(\delta) = \int m(z, a, w)g_{\delta}(a\mid w)p(z,w) d\nu(a,z,w),
  \end{equation*}
  for outcome mechanism $m(z,a,w)$ and post-intervention treatment mechanism
  $g_{\delta}(a\mid w)$ --- a stochastic intervention drawing
  $A_{\delta} \sim g_{\delta}(a \mid w)$ while letting mediator $Z$ take on its
  natural value.
\item Letting $\eta = (g, e, m, \phi)$, the efficient influence function for
  $\theta(\delta)$ in the nonparametric model $\mathcal{M}$ is
  $D^Y_{\eta, \delta}(o) + D^A_{\eta, \delta}(o) + D^{Z, W}_{\eta, \delta}(o) -
  \theta(\delta)$ for
  \vspace{-0.5em}
  \begin{align*}
    D^{Z, W}_{\eta, \delta}(o) &= \int m(z, a, w) g_{\delta}(a \mid w)
      d\kappa(a),
    \quad
    D^Y_{\eta, \delta}(o) = \mathbf{\textcolor{blue}{\frac{g_{\delta}(a \mid w)}
      {e(a \mid z, w)}}} \{y - m(z,a,w) \},\\
    D^A_{\eta,\delta}(o) &= \frac{\mathbf{\textcolor{red}{\delta\phi(w)}}\{a -
      g(1 \mid w)\}}{\mathbf{\textcolor{red}{\{\delta g(1 \mid w) +
      g(0 \mid w)\}^2}}},
    \quad
    \phi(w) = \mathbb{E}\left\{m(1, Z, W) - m(0, Z, W) \mid W = w \right\},
  \end{align*}
  where, for simplicity, we present the case $A \in \{0, 1\}$. For an unabridged
  treatment, see \cite{diaz2019causal}.
\end{itemize}
\vspace{0.5cm} % When there are two boxes, some whitespace may need to be added
                % if the one on the right has more content
}

%-------------------------------------------------------------------------------
\end{poster}
\end{document}
